{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58661a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# get project root (one folder up from notebooks/)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3846881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\OneDrive\\Desktop\\Mini Lens Google\\Google-lens-mini\\lens\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from modules.preprocessing import preprocessing_image\n",
    "from modules.ocr_engine import run_best_ocr\n",
    "from modules.vision_signals import extract_vision_signals\n",
    "from modules.fusion import fuse_signals\n",
    "from modules.embeddings import build_faiss_index, load_vectorstore\n",
    "from modules.rag_pipeline import rag_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb1378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r\"C:\\Users\\Dell\\OneDrive\\Pictures\\Mobilenetv2.png\"\n",
    "image_id = os.path.splitext(os.path.basename(img_path))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674c6f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\Dell\\OneDrive\\Desktop\\Mini Lens Google\\Google-lens-mini\\lens\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Dell\\OneDrive\\Desktop\\Mini Lens Google\\Google-lens-mini\\lens\\Lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:717: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\Dell\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\Dell\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\Dell\\.paddlex\\official_models\\PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\Dell\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\Dell\\.paddlex\\official_models\\en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Engine: EasyOCR\n",
      "OCR Results: [{'text': 'n = 1280', 'conf': 0.9979261928051756, 'bbox': [[np.int32(757), np.int32(25)], [np.int32(827), np.int32(25)], [np.int32(827), np.int32(45)], [np.int32(757), np.int32(45)]]}, {'text': 'n =', 'conf': 0.5405014157295227, 'bbox': [[np.int32(339), np.int32(87)], [np.int32(367), np.int32(87)], [np.int32(367), np.int32(101)], [np.int32(339), np.int32(101)]]}, {'text': '32', 'conf': 0.9999996628252286, 'bbox': [[np.int32(365), np.int32(83)], [np.int32(389), np.int32(83)], [np.int32(389), np.int32(103)], [np.int32(365), np.int32(103)]]}]\n"
     ]
    }
   ],
   "source": [
    "versions = preprocessing_image(img_path)\n",
    "ocr_result = run_best_ocr(img_path, preprocessed_img=versions[\"enhanced\"])\n",
    "print(\"OCR Engine:\", ocr_result[\"engine\"])\n",
    "print(\"OCR Results:\", ocr_result[\"results\"][:3])  # preview first 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08767b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Dell\\OneDrive\\Pictures\\Mobilenetv2.png: 288x640 (no detections), 139.0ms\n",
      "Speed: 4.4ms preprocess, 139.0ms inference, 13.4ms postprocess per image at shape (1, 3, 288, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vision Result: {'objects': [], 'qr_codes': [], 'caption': 'a diagram of the cell membrane'}\n"
     ]
    }
   ],
   "source": [
    "vision_result = extract_vision_signals(img_path)\n",
    "print(\"Vision Result:\", vision_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef72fb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Text:\n",
      " {'fusion_text': 'This image contains:\\n    - OCR text: n = 1280 n = 32 n = 96 n = 1280 128x128x3 128x128 64 x 64 32 x 32 Softmax Fully Connected Classifier MobileNetv2 Preprocessing 3x3 Conv, ReLU Max pool 2x2 [\\n    - Detected objects: None\\n    - QR codes: None\\n    - Caption: a diagram of the cell membrane', 'fusion_json': {'id': 'Mobilenetv2', 'ocr_text': 'n = 1280 n = 32 n = 96 n = 1280 128x128x3 128x128 64 x 64 32 x 32 Softmax Fully Connected Classifier MobileNetv2 Preprocessing 3x3 Conv, ReLU Max pool 2x2 [', 'objects': [], 'qr_codes': [], 'caption': 'a diagram of the cell membrane'}}\n"
     ]
    }
   ],
   "source": [
    "fusion_text = fuse_signals(\n",
    "    image_id=image_id,\n",
    "    ocr_results=ocr_result[\"results\"],\n",
    "    vision_results=vision_result\n",
    ")\n",
    "print(\"Fusion Text:\\n\", fusion_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c15c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\OneDrive\\Desktop\\Mini Lens Google\\Google-lens-mini\\lens\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved index to data/vectorstore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "build_faiss_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80c04552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\OneDrive\\Desktop\\Mini Lens Google\\Google-lens-mini\\lens\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What does the diagram show?\n",
      "A: cell membrane [ Objects: QR: Caption: a diagram of the cell membrane Image ID: receipt_001 OCR: n = 1280 n = 32 n = 96 n = 1280 128x128x3 128x128 64 x 64 32 x 32 Softmax Fully Connected Classifier MobileNetv2 Preprocessing 3x3 Conv, ReLU Max pool 2x2 [ Objects: QR: Caption: a diagram of the cell membrane Image ID: receipt_001 OCR: n = 1280 n = 32 n = 96 n = 1280 128x128x3 128x128 64 x 64 32 x 32 Softmax Fully Connected Classifier MobileNetv2 Preprocessing 3x3 Conv, ReLU Max pool 2x2 [ Objects: QR: Caption: a\n",
      "Retrieved Context: [{'score': 0.27438050508499146, 'chunk_id': 'receipt_001_c0', 'image_id': 'receipt_001', 'text': 'Image ID: receipt_001\\n        OCR: n = 1280 n = 32 n = 96 n = 1280 128x128x3 128x128 64 x 64 32 x 32 Softmax Fully Connected Classifier MobileNetv2 Preprocessing 3x3 Conv, ReLU Max pool 2x2 [\\n        Objects: \\n        QR: \\n        Caption: a diagram of the cell membrane'}, {'score': 0.25264376401901245, 'chunk_id': 'Mobilenetv2_c0', 'image_id': 'Mobilenetv2', 'text': 'Image ID: Mobilenetv2\\n        OCR: n = 1280 n = 32 n = 96 n = 1280 128x128x3 128x128 64 x 64 32 x 32 Softmax Fully Connected Classifier MobileNetv2 Preprocessing 3x3 Conv, ReLU Max pool 2x2 [\\n        Objects: \\n        QR: \\n        Caption: a diagram of the cell membrane'}, {'score': -3.4028234663852886e+38, 'chunk_id': 'receipt_001_c0', 'image_id': 'receipt_001', 'text': 'Image ID: receipt_001\\n        OCR: n = 1280 n = 32 n = 96 n = 1280 128x128x3 128x128 64 x 64 32 x 32 Softmax Fully Connected Classifier MobileNetv2 Preprocessing 3x3 Conv, ReLU Max pool 2x2 [\\n        Objects: \\n        QR: \\n        Caption: a diagram of the cell membrane'}]\n"
     ]
    }
   ],
   "source": [
    "retriever = load_vectorstore()\n",
    "question = \"What does the diagram show?\"\n",
    "answer, retrieved = rag_query(question, retriever)\n",
    "\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", answer)\n",
    "print(\"Retrieved Context:\", retrieved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262fca6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0df0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
